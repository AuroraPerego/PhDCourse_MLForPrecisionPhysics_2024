{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d1be670-b5d2-4ffa-8074-8f517e85b849",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import Transformer\n",
    "from torch.nn import TransformerEncoderLayer, TransformerDecoderLayer\n",
    "from torch.nn import TransformerEncoder, TransformerDecoder\n",
    "\n",
    "from libs.transformer_models import count_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e0cc6a8-a937-4a5c-ae55-8b63f2e7e378",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.rand((128, 10, 16)) # [B, T, F] [batch, token, feature]\n",
    "tokens = torch.rand((128, 4, 16))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f6d9fb0-8b4b-4b85-8d83-3b408c21e901",
   "metadata": {},
   "source": [
    "# Encoder only"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef9d426f-936e-4b91-a23d-88a991c347e1",
   "metadata": {},
   "source": [
    "Play with the transformer parameters and try to break it. \n",
    "Are the input dimensions compatible?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e46db60c-0d26-4e87-95ca-150663108bc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34960"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = TransformerEncoderLayer(d_model = 16,\n",
    "                                  nhead = 4,\n",
    "                                  dim_feedforward= 1024, \n",
    "                                  dropout = 0.1,\n",
    "                                  batch_first=True)\n",
    "count_parameters(encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a3ffb139-f30b-4a2b-b318-d5fa10d793f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 10, 16])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_encoder = encoder(X)\n",
    "out_encoder.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bee25fac-11d0-4dc6-9372-f69ab7fc6d14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransformerEncoderLayer(\n",
       "  (self_attn): MultiheadAttention(\n",
       "    (out_proj): NonDynamicallyQuantizableLinear(in_features=16, out_features=16, bias=True)\n",
       "  )\n",
       "  (linear1): Linear(in_features=16, out_features=1024, bias=True)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (linear2): Linear(in_features=1024, out_features=16, bias=True)\n",
       "  (norm1): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
       "  (norm2): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
       "  (dropout1): Dropout(p=0.1, inplace=False)\n",
       "  (dropout2): Dropout(p=0.1, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "921d8799-a64f-49c1-92ba-a93e84102da3",
   "metadata": {},
   "source": [
    "## Stack of encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b8dbfb0f-f915-4bd4-8bda-c4d7b56f0a2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "139840"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_stack = TransformerEncoder(encoder, num_layers=4)\n",
    "count_parameters(encoder_stack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d0d11ca1-cda2-4bfe-8be8-d937b2682ba0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 10, 16])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_encoder = encoder_stack(X)\n",
    "out_encoder.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4f1c8557-658c-4bee-b49f-727a0f11b385",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransformerEncoder(\n",
       "  (layers): ModuleList(\n",
       "    (0-3): 4 x TransformerEncoderLayer(\n",
       "      (self_attn): MultiheadAttention(\n",
       "        (out_proj): NonDynamicallyQuantizableLinear(in_features=16, out_features=16, bias=True)\n",
       "      )\n",
       "      (linear1): Linear(in_features=16, out_features=1024, bias=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (linear2): Linear(in_features=1024, out_features=16, bias=True)\n",
       "      (norm1): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout1): Dropout(p=0.1, inplace=False)\n",
       "      (dropout2): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_stack"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "518a57a6-ca3d-4477-851a-427e678b3d92",
   "metadata": {},
   "source": [
    "# Full Transformer (with decoder)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c5471d-1edf-45ae-8445-5e9686437b3b",
   "metadata": {},
   "source": [
    "When using an encoder and decoder architecture, the number of decoder input tokens can be different than the number of input tokens for the encoder.\n",
    "\n",
    "![](data:image/png;base64,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)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f65c86f5-947a-4318-863e-751ec7615092",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "142144"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer = Transformer(d_model = 16,\n",
    "                          nhead = 4,\n",
    "                          num_encoder_layers = 2,\n",
    "                          num_decoder_layers = 2,\n",
    "                          dim_feedforward = 1024,\n",
    "                          batch_first = True)  # transformer will have [B, T, F],if not [T, B, F]\n",
    "\n",
    "count_parameters(transformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "27dac106-dd03-4201-a68e-c720341d057f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 4, 16])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = transformer(src=X, tgt=tokens)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b1d4e6f8-5130-4527-b132-e877971ac145",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Transformer(\n",
       "  (encoder): TransformerEncoder(\n",
       "    (layers): ModuleList(\n",
       "      (0-1): 2 x TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=16, out_features=16, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=16, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=1024, out_features=16, bias=True)\n",
       "        (norm1): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (decoder): TransformerDecoder(\n",
       "    (layers): ModuleList(\n",
       "      (0-1): 2 x TransformerDecoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=16, out_features=16, bias=True)\n",
       "        )\n",
       "        (multihead_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=16, out_features=16, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=16, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=1024, out_features=16, bias=True)\n",
       "        (norm1): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm3): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        (dropout3): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85794251-3256-4740-afc5-34fbfbfe5509",
   "metadata": {},
   "source": [
    "## Transformer with src padding mask\n",
    "Sometimes we need to mask some of the input tokens: we want to exclude them from the transformer attention computation. \n",
    "There may be 2 cases:\n",
    "- masking for padding : variable number of jets\n",
    "- masking for casual relations: for example we don't want that a token can \"see\" tokens coming after in the input set. (Casual mask)\n",
    "\n",
    "Docs: https://pytorch.org/docs/stable/generated/torch.nn.Transformer.html#torch.nn.Transformer.forward"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8051eb53-96bf-46d5-b50e-437bbcb05b88",
   "metadata": {},
   "source": [
    "### Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0171f725-5c3b-4e83-b290-99bf47311c1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False, False, False,  ...,  True,  True,  True],\n",
       "        [False, False, False,  ...,  True,  True,  True],\n",
       "        [False, False, False,  ...,  True,  True,  True],\n",
       "        ...,\n",
       "        [False, False,  True,  ...,  True,  True,  True],\n",
       "        [False, False,  True,  ...,  True,  True,  True],\n",
       "        [False, False,  True,  ...,  True,  True,  True]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.rand((128, 10, 16))\n",
    "tokens = torch.rand((128, 10, 16))\n",
    "\n",
    "pad_mask = torch.zeros((128,10), dtype=bool)\n",
    "# Removing some inputs\n",
    "pad_mask[0:64, 7:] = True\n",
    "pad_mask[64:, 2:] = True\n",
    "pad_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "78f4e080-129c-4507-9b60-ea73ed8e0653",
   "metadata": {},
   "outputs": [],
   "source": [
    "out1 = encoder_stack(X, src_key_padding_mask=pad_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ffd6db69-8851-4f3f-ac5c-ffbf500b9a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xnew = torch.clone(X)\n",
    "Xnew[0:64, 7:, 0] = 0.\n",
    "encoder_stack.eval()\n",
    "out1 = encoder_stack(X, src_key_padding_mask=pad_mask)\n",
    "out2 = encoder_stack(Xnew, src_key_padding_mask=pad_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "10adfd50-0739-4ca1-a6e8-407580e69f76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True],\n",
       "        [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True],\n",
       "        [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True],\n",
       "        [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True],\n",
       "        [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True],\n",
       "        [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True],\n",
       "        [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True],\n",
       "        [False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False],\n",
       "        [False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False],\n",
       "        [False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out1[0] == out2[0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b3aba463-ac4a-46f5-b720-32d3ac063f5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.9066,  0.3626,  0.8220,  0.4059,  1.4774, -1.2843, -0.5732,  1.4198,\n",
       "         -0.2927,  0.5273,  0.6085, -1.8958, -1.2237,  0.5119, -0.4552, -1.3171],\n",
       "        [-0.9259,  0.2171,  1.0379, -0.8275,  1.6811, -0.7857, -0.1984,  1.3855,\n",
       "         -0.6541,  0.9465,  1.3945, -1.0106, -1.2616,  0.5444, -0.2409, -1.3022],\n",
       "        [ 0.0142, -0.7912,  0.8817,  0.6903,  0.8482, -0.5841, -0.9625,  1.9716,\n",
       "          0.2848,  0.6822, -0.0732, -2.5445, -0.9628,  0.2819,  0.4300, -0.1666]],\n",
       "       grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out1[0][7:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c02511f2-bb88-4e80-bd2f-0c40f485d4ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.4497,  0.1102,  0.9989,  1.0296,  1.0400, -0.8519, -0.2028,  1.9405,\n",
       "         -0.4279,  0.2218,  0.3419, -2.1688, -1.2552,  0.8386, -0.3559, -0.8093],\n",
       "        [-0.9444,  0.2158,  1.0421, -0.8190,  1.6741, -0.7760, -0.1957,  1.3958,\n",
       "         -0.6621,  0.9419,  1.3901, -1.0168, -1.2592,  0.5492, -0.2414, -1.2944],\n",
       "        [-0.6300, -0.8862,  0.9273,  0.9758,  0.4389, -0.4272, -0.6692,  1.9883,\n",
       "          0.2503,  0.5958, -0.1366, -2.5533, -0.9002,  0.5052,  0.4509,  0.0701]],\n",
       "       grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out2[0][7:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "411f0377-97ed-44ac-b170-acf4ef1199d0",
   "metadata": {},
   "source": [
    "### Casual mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e270f970-ed04-4b61-9e80-abdf6bd236dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False,  True,  True,  True,  True,  True,  True,  True,  True,  True],\n",
       "        [False, False,  True,  True,  True,  True,  True,  True,  True,  True],\n",
       "        [False, False, False,  True,  True,  True,  True,  True,  True,  True],\n",
       "        [False, False, False, False,  True,  True,  True,  True,  True,  True],\n",
       "        [False, False, False, False, False,  True,  True,  True,  True,  True],\n",
       "        [False, False, False, False, False, False,  True,  True,  True,  True],\n",
       "        [False, False, False, False, False, False, False,  True,  True,  True],\n",
       "        [False, False, False, False, False, False, False, False,  True,  True],\n",
       "        [False, False, False, False, False, False, False, False, False,  True],\n",
       "        [False, False, False, False, False, False, False, False, False, False]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_len = tokens.size(1)\n",
    "casual_mask = torch.triu(torch.ones(seq_len, seq_len), diagonal=1).bool()\n",
    "casual_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4e30ed6d-a2fb-4556-8dc2-4983218e711d",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer.eval()\n",
    "out1 = transformer(src=X, tgt=tokens, tgt_mask=casual_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7518229d-0a86-446e-9659-b92e219a5f3a",
   "metadata": {},
   "source": [
    "If we change the value of the second token the first output should remain the same. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ac73549c-b908-4e4a-96be-5a4062ae3877",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens[:,1] = 5000\n",
    "out2 = transformer(src=X, tgt=tokens, tgt_mask=casual_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d9ac8efc-a93e-4aa2-8849-fc2e9c867370",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[True, True, True,  ..., True, True, True],\n",
       "        [True, True, True,  ..., True, True, True],\n",
       "        [True, True, True,  ..., True, True, True],\n",
       "        ...,\n",
       "        [True, True, True,  ..., True, True, True],\n",
       "        [True, True, True,  ..., True, True, True],\n",
       "        [True, True, True,  ..., True, True, True]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out1[:,0] == out2[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "cea9f635-b532-40ce-b18d-82297c494c8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False, False, False,  ..., False, False, False],\n",
       "        [False, False, False,  ..., False, False, False],\n",
       "        [False, False, False,  ..., False, False, False],\n",
       "        ...,\n",
       "        [False, False, False,  ..., False, False, False],\n",
       "        [False, False, False,  ..., False, False, False],\n",
       "        [False, False, False,  ..., False, False, False]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out1[:,1] == out2[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eddf355b-2778-4824-887d-6405b5299561",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
